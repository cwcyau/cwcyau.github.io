<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Explainable Algorithms | Yau Research Group</title>
    <link>https://cwcyau.github.io/tag/explainable-algorithms/</link>
      <atom:link href="https://cwcyau.github.io/tag/explainable-algorithms/index.xml" rel="self" type="application/rss+xml" />
    <description>Explainable Algorithms</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 01 Jan 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://cwcyau.github.io/media/icon_hu11734318148517933569.png</url>
      <title>Explainable Algorithms</title>
      <link>https://cwcyau.github.io/tag/explainable-algorithms/</link>
    </image>
    
    <item>
      <title>Convolutional filtering for mutation signatures</title>
      <link>https://cwcyau.github.io/event/convsig/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://cwcyau.github.io/event/convsig/</guid>
      <description>&lt;p&gt;Mutation signatures are the hallmarks of mutagenic processes in cancer that can provide clues about the biochemical mechanisms by which DNA is altered in cancer. The extraction of such signatures from next generation sequencing data has traditionally been formulated as an unsupervised learning problem and solved using non-negative matrix factorization. We present an entirely novel approach based on convolutional filtering, inspired by technologies used in computer vision and image processing for genomic data analysis. We show that our approach has state-of-the-art performance compared to standard methods but also generalizes to allow consideration of larger sequence contexts using deep layering of convolutional networks providing a tool that could potentially reveal the impact of high-level genome structure on mutational density.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Researchers:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cwcyau.github.io/authors/feng/&#34;&gt;Yun Feng&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Neural Decomposition</title>
      <link>https://cwcyau.github.io/event/neural-decomp/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://cwcyau.github.io/event/neural-decomp/</guid>
      <description>&lt;p&gt;Neural network models for dimensionality reduction, such as Variational AutoEncoders (VAEs), can identify latent low-dimensional structures embedded within high-dimensional data. These low-dimensional representations can provide some insight into patterns within datasets but their interpretation relies on how these map back on the original feature set. However the latter requires interpreting what the decoder network has learnt which makes it challenging.&lt;/p&gt;
&lt;p&gt;In this project, we have focused on understanding the sources of variation in Conditional VAEs. Our goal is to &lt;em&gt;decompose&lt;/em&gt; the feature-level variation in high-dimensional data through disentanglement of additive and interactions effects of latent variables and fixed inputs. We propose to achieve this through the &lt;em&gt;Neural Decomposition&lt;/em&gt; - an adaptation of the well-known concept of variance decomposition from classical statistics to deep learning models. We show that &lt;em&gt;identifiable&lt;/em&gt; Neural Decomposition relies on training models subject to constraints on the marginal properties of the neural networks whilst naive implementations will lead to non-identifiable models.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Researchers:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cwcyau.github.io/authors/kaspar/&#34;&gt;Kaspar Maertens&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>RLevolution</title>
      <link>https://cwcyau.github.io/event/rlevolution/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://cwcyau.github.io/event/rlevolution/</guid>
      <description>&lt;p&gt;Genomic copy number evolution in cancer refers to the acquisition or loss of genome segments over time due to mutational processes in cancer that result in the loss of biological mechanisms for the maintenance of genome integrity in cells. Genome sequencing can allow us to detect these copy number alterations in cancer cells but do not directly inform us what the sequence of evolutionary events was that led to the present state of the cancer. We have developed a novel, first-of-its-kind reinforcement learning based approach for inferring evolutionary trajectories from genomic copy number profiles which we call \RLEvolution. We show that \RLEvolution is able to deconvolve the sequence of complex events that may occur during cancer evolution using a combination of simulated and real-world cancer datasets.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Researchers:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cwcyau.github.io/authors/feng/&#34;&gt;Yun Feng&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The Automatic BioData Scientist</title>
      <link>https://cwcyau.github.io/event/neural-odes/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://cwcyau.github.io/event/neural-odes/</guid>
      <description>&lt;p&gt;Mathematical models of disease evolution seek to specify the complex mechanistic relationships between many measurable quantities over space and time. However, as our capability to generate experimental data improves, our ability to conceive of appropriate mathematical descriptions to describe biological phenomena has become a bottleneck.&lt;/p&gt;
&lt;p&gt;The goal of machine learning is to “learn” complex dependencies automatically within data sets.  Neural networks (NNs) have been at the forefront of recent advances by offering a means of parametrising complex functional mapping between data and its representations.&lt;/p&gt;
&lt;p&gt;Novel computational machinery have enabled NN approaches to scale to the analysis of unprecedently large datasets and provide versatility over standard modelling approaches. However, despite their successes in a range of applications, in biomedical research, NNs are often derided for their “black box” discoveries, lack of interpretability and the need for unrealistic quantities of training data. Such criticisms often overlook the fact that default NN structures express no explicit assumptions about the problems on which they are applied and they are often used as generic data mining devices for discovery purposes.&lt;/p&gt;
&lt;p&gt;Nonetheless, there is a clear opportunity for the development of novel NN approaches that combine scalability and versatility with the capability of learning the physically realistic constraints that are embedded in hand-crafted mathematical models.&lt;/p&gt;
&lt;p&gt;This project seeks to investigate the methodological foundations for what could form an &lt;em&gt;Automated BioData Scientist&lt;/em&gt; (AutoBioDataSci) platform. We would like to develop learning algorithms that can capture biological laws and encapsulate them in such a way that such knowledge can be transfer to new problems. This major project involves inter-linking representation learning theory with transfer and meta-learning as well as having its roots embedded in the biological scientific discovery process.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Researchers:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cwcyau.github.io/authors/danks/&#34;&gt;Dominic Danks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cwcyau.github.io/authors/kaspar/&#34;&gt;Kaspar Maertens&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
